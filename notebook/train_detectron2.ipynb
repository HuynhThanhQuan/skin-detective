{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1721f095-b896-456c-87b5-c1f2d8beea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n",
      "torch:  2.1 ; cuda:  cu121\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import detectron2\n",
    "\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ee6a15-6e5a-4a80-9470-7fbe73055099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e6f77d-e798-4f35-996a-be680b5c02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca33d2f-9482-4685-9ccb-1a97dc6c9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98087a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(f'acne_train', {}, '/home/quan/work/skin-detective/data/dataset/20240208/train.json', '/home/quan/work/skin-detective/data/filtered/circle')\n",
    "register_coco_instances(f'acne_test', {}, '/home/quan/work/skin-detective/data/dataset/20240208/test.json', '/home/quan/work/skin-detective/data/filtered/circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ee4b5b-6ee7-4d46-9028-d36b14841515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/08 19:33:17 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[02/08 19:33:17 d2.data.datasets.coco]: \u001b[0mLoaded 736 images in COCO format from /home/quan/work/skin-detective/data/dataset/20240208/train.json\n"
     ]
    }
   ],
   "source": [
    "acne_train_ds = DatasetCatalog.get('acne_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb75ff-6445-486f-a449-2771320f7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetadataCatalog.get('acne_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a671e51-6ddb-4abd-8732-43412a3582a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in acne_ds[:2]:\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    visualizer = Visualizer(img[:, :, ::-1], scale=1)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33818c-ac15-486d-8bc1-16e831297942",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af2d5a-ee30-474b-8425-d61e3eeecfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"acne_train\",)\n",
    "cfg.DATASETS.TEST = (\"acne_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 30    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5 # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeda417-3483-4341-acff-4b35a0e43341",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456175b5-7fdc-4036-83ce-e92a670f7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf98ec-3091-4707-b5cc-1f34f37885f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c6956-91f6-442b-9f14-3a7b427ae48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "dataset_dicts = DatasetCatalog.get('acne_val')\n",
    "for d in random.sample(dataset_dicts, 2):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im) \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe9d41-3b12-435d-b0b5-950fafe98935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"acne_val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"acne_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a53b5-01f0-42ed-859b-504fcadc297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = COCOEvaluator(\"acne_test\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"acne_test\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f7747-3a0e-4be7-ae0b-afb4d180b038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
