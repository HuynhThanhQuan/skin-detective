{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import argparse\n",
    "import shutil\n",
    "import collections\n",
    "import subprocess\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSIFIER = 'lgbm_20211223'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDED_BLUE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'dát_tăng_sắc_tố_(vết_thâm)': 0,\n",
    "    'sang_thương_viêm_(sẩn,_mụn_mủ,_mảng_viêm_đỏ)': 1,\n",
    "    'sẹo_mụn_(lõm,_lồi)': 2,\n",
    "    'còi_(đóng/mở)': 3,\n",
    "    'sang_thương_nang_và_nốt': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: 'vet_tham',\n",
    "    1: 'thuong_viem',\n",
    "    2: 'seo_mun',\n",
    "    3: 'coi',\n",
    "    4: 'thuong_nang'\n",
    "}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float\n",
    "id2color = {\n",
    "    0: (0.1, 0.1, 0.7), #blue-black\n",
    "    1: (1.0,0.5,1.0), #pink\n",
    "    2: (0, 0.6, 0), #green\n",
    "    3: (0.4, 0.9, 0.9), #light blue\n",
    "    4: (0.9, 0, 0) #red\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_check(x):\n",
    "    if os.path.isdir(x):\n",
    "        return False\n",
    "    with open(x, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if (len(lines) == 0):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = os.listdir('/hdd2/skin/app_data/bbox/')\n",
    "d = pd.DataFrame({'id': img_ids})\n",
    "d['coco'] = d['id'].apply(lambda x: os.path.join('/hdd2/skin/app_data/bbox/', x))\n",
    "d['coco_check'] = d['coco'].apply(lambda x: os.path.exists(x))\n",
    "d['image'] = d['id'].apply(lambda x: os.path.join('/hdd2/skin/app_data/bbox_img/', x + '.jpg'))\n",
    "d['image_check'] = d['image'].apply(lambda x: os.path.exists(x))\n",
    "d['object_check'] = d['coco'].apply(lambda x: object_check(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_ids), img_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('/hdd2/skin/app_data/bbox_img/')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[['coco_check', 'image_check', 'object_check']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(os.listdir('/hdd2/skin/app_data/bbox_img'))\n",
    "\n",
    "# len(os.listdir('/hdd2/skin/app_data/bbox_img'))\n",
    "\n",
    "# len(os.listdir('/hdd2/skin/app_data/data1/images_1'))\n",
    "\n",
    "# len(os.listdir('/hdd2/skin/app_data/data2/images'))\n",
    "\n",
    "# len(os.listdir('/hdd2/skin/app_data/CIRCLE_01/images_bbox_1'))\n",
    "\n",
    "# len(os.listdir('/hdd2/skin/app_data/CIRCLE_02/images_bbox_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[(d['coco_check'] == True) & (d['image_check'] == True) & (d['object_check'] == True)]\n",
    "d = d.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_d = pd.read_csv('grade.xls', index_col=0)\n",
    "grad_d = grad_d.rename(columns={'Grade': 'grading', 'ID': 'id'})\n",
    "grad_d = grad_d[grad_d['grading'].isin(['0','1','2','3','4'])]\n",
    "grad_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_d['grading'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.merge(grad_d[['id', 'grading']], left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['grading'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSPECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(img_id, plot_im=True):\n",
    "    img_path = d[d['id'] == img_id]['image'].tolist()[0]\n",
    "    bbox_tuple = read_coco(img_id)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_copy = deepcopy(img)\n",
    "    labels, x0s, y0s, x1s, y1s = bbox_tuple\n",
    "    for i, (x0, y0, x1, y1) in enumerate(zip(x0s, y0s, x1s, y1s)):\n",
    "        cv2.rectangle(img_copy, (x0, y0), (x1, y1), (0, 0, 255), 5)\n",
    "    if plot_im:\n",
    "        plot_img(img_copy)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_content(file_content):\n",
    "    lines = file_content\n",
    "    labels, x0s, y0s, x1s, y1s = [], [], [], [], []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        elements = line.split(' ')\n",
    "        label, x0, y0, x1, y1 = elements\n",
    "        x0 = int(x0)\n",
    "        y0 = int(y0)\n",
    "        x1 = int(x1)\n",
    "        y1 = int(y1)\n",
    "        labels.append(label)\n",
    "        x0s.append(x0)\n",
    "        y0s.append(y0)\n",
    "        x1s.append(x1)\n",
    "        y1s.append(y1)\n",
    "    return (labels, x0s, y0s, x1s, y1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_coco(img_id):\n",
    "    path = d[d['id'] == img_id]['coco'].tolist()[0]\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        return read_content(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = draw_bounding_boxes('ckls4ugoq00gq3a68u5ddifuw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, d, transforms=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_ids = d[\"id\"].unique()\n",
    "        self.df = d\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        labels, x0s, y0s, x1s, y1s = read_coco(image_id)\n",
    "        \n",
    "        image = cv2.imread(self.df[self.df['id'] == image_id]['image'].tolist()[0])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image/255.0\n",
    "        image = image.transpose(2,0,1)\n",
    "        image = torch.from_numpy(image).float()\n",
    "       \n",
    "        boxes = np.array(list(zip(x0s, y0s, x1s, y1s)))\n",
    "        if boxes.shape == (0,):\n",
    "            print(index, len(self.df), image_id, boxes.shape, labels, x0s, y0s, x1s, y1s)\n",
    "            raise Exception('Wrong format')\n",
    "        labels = torch.tensor([label2id[l] for l in labels], dtype=torch.int64)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        num_objs = len(boxes)\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = torch.from_numpy(boxes)\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        target[\"area\"] = torch.from_numpy(area)\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP(test_dataset, test_data_loader, threshold=0.3):\n",
    "    it_data_loader = iter(test_data_loader)\n",
    "    det_image_ids = list()\n",
    "    det_boxes = list()\n",
    "    det_labels = list()\n",
    "    det_scores = list()\n",
    "    true_boxes = list()\n",
    "    true_labels = list()\n",
    "    true_difficulties = list()\n",
    "    idx = 0\n",
    "    for i in range(len(test_dataset)):\n",
    "        images, targets = next(it_data_loader)\n",
    "        images = list(img.to(device) for img in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        image_ids = [k['image_id'] for k in targets]\n",
    "        preds = model(images)\n",
    "        preds = [{k: v.to(cpu) for k, v in t.items()} for t in preds]\n",
    "        boxes = targets[idx]['boxes'].cpu().numpy().astype(np.int32)\n",
    "        image = images[idx].cpu().numpy()\n",
    "        image = image.transpose(1,2,0)\n",
    "        pred_scores, pred_boxes, pred_classes = get_prediction(preds[idx], threshold)\n",
    "        pred_boxes = pred_boxes.astype(np.int32)\n",
    "        det_boxes_batch = torch.from_numpy(pred_boxes)\n",
    "        det_labels_batch = torch.from_numpy(pred_classes)\n",
    "        det_scores_batch = torch.from_numpy(pred_scores)\n",
    "        boxes = targets[idx]['boxes']\n",
    "        labels = targets[idx]['labels']\n",
    "        det_boxes.append(det_boxes_batch)\n",
    "        det_labels.append(det_labels_batch)\n",
    "        det_scores.append(det_scores_batch)\n",
    "        true_boxes.append(boxes)\n",
    "        true_labels.append(labels)\n",
    "        det_image_ids.extend(image_ids)\n",
    "    copy2voc(test_dataset, det_image_ids, true_labels, true_boxes, det_labels, det_scores, det_boxes)\n",
    "    result = subprocess.run([\"python\", \"pascalvoc.py\", \"-t\", \"0.1\"], cwd=\"/hdd2/skin/app_data/lab1/mAP\", capture_output=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy2voc(selected_dataset, det_image_ids, true_labels, true_boxes, det_labels, det_scores, det_boxes):\n",
    "    shutil.rmtree('/hdd2/skin/app_data/lab1/mAP/detections')\n",
    "    shutil.rmtree('/hdd2/skin/app_data/lab1/mAP/groundtruths')\n",
    "    shutil.rmtree('/hdd2/skin/app_data/lab1/mAP/results')\n",
    "    os.makedirs('/hdd2/skin/app_data/lab1/mAP/detections')\n",
    "    os.makedirs('/hdd2/skin/app_data/lab1/mAP/groundtruths')\n",
    "    os.makedirs('/hdd2/skin/app_data/lab1/mAP/results')\n",
    "\n",
    "    for i, tl, tb, dl, ds, db in zip(det_image_ids, true_labels, true_boxes, det_labels, det_scores, det_boxes):\n",
    "        idx = i.cpu().numpy()[0]\n",
    "        fn = selected_dataset.image_ids[idx] + '.txt'\n",
    "        # Write groundtruth content\n",
    "        gt_fn = os.path.join('/hdd2/skin/app_data/lab1/mAP/groundtruths', fn)\n",
    "        with open(gt_fn, 'w') as gt_file:\n",
    "            lines = []\n",
    "            for j in range(len(tl)):\n",
    "                _id = tl[j].cpu().numpy().tolist()\n",
    "                if _id != 0 or EXCLUDED_BLUE is False:\n",
    "                    label = id2label[_id]\n",
    "                    x0 = tb[j].cpu().numpy()[0]\n",
    "                    y0 = tb[j].cpu().numpy()[1]\n",
    "                    x1 = tb[j].cpu().numpy()[2]\n",
    "                    y1 = tb[j].cpu().numpy()[3]\n",
    "                    line = f'{label} {x0} {y0} {x1} {y1}'\n",
    "                    lines.append(line)\n",
    "            content = '\\n'.join(lines)\n",
    "            gt_file.writelines(content)\n",
    "\n",
    "        # Write detection content\n",
    "        dt_fn = os.path.join('/hdd2/skin/app_data/lab1/mAP/detections', fn)\n",
    "        with open(dt_fn, 'w') as dt_file:\n",
    "            lines = []\n",
    "            for j in range(len(dl)):\n",
    "                label = id2label[dl[j].cpu().numpy().tolist()]\n",
    "                score = ds[j].cpu().numpy()\n",
    "                x0 = db[j].cpu().numpy()[0]\n",
    "                y0 = db[j].cpu().numpy()[1]\n",
    "                x1 = db[j].cpu().numpy()[2]\n",
    "                y1 = db[j].cpu().numpy()[3]\n",
    "                line = f'{label} {score} {x0} {y0} {x1} {y1}'\n",
    "                lines.append(line)\n",
    "            content = '\\n'.join(lines)\n",
    "            dt_file.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AppDataset(d, get_valid_transform())\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "device = torch.device('cuda:1')\n",
    "cpu, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../model_FRCNN50/resnet50_epoch12700.pkl', map_location=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(label2id)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(pred_dict, threshold=0.3, topk=3):\n",
    "    pred_class = pred_dict['labels'].detach().numpy()\n",
    "    pred_boxes = pred_dict['boxes'].detach().numpy()\n",
    "    pred_score = pred_dict['scores'].detach().numpy()\n",
    "    pred_t = pred_score >= threshold\n",
    "    pred_boxes = pred_boxes[pred_t]\n",
    "    pred_class = pred_class[pred_t]\n",
    "    pred_scores = pred_score[pred_t]\n",
    "    return pred_scores, pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_bbox(img, gt_boxes, gt_classes, pred_boxes, pred_class, plot_bbox=False, plot_class=True):\n",
    "    linewidth = img.shape[0]//500\n",
    "    if plot_bbox:\n",
    "        img_copy1 = deepcopy(img)\n",
    "        img_copy2 = deepcopy(img)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(24, 14))\n",
    "        for box, _class in zip(gt_boxes, gt_classes):\n",
    "            cv2.rectangle(img_copy1, (box[0], box[1]), (box[2], box[3]), (0, 255, 255), linewidth)\n",
    "        for box, _class in zip(pred_boxes, pred_class):\n",
    "            cv2.rectangle(img_copy2, (box[0], box[1]), (box[2], box[3]), (255, 0, 255), linewidth)\n",
    "        hstack_np = np.hstack((img, img_copy1, img_copy2))\n",
    "        ax.imshow(hstack_np)\n",
    "    if plot_class:\n",
    "        img_copy1 = deepcopy(img)\n",
    "        img_copy2 = deepcopy(img)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(24, 14))\n",
    "        for box, _class in zip(pred_boxes, pred_class):\n",
    "            cv2.rectangle(img_copy2, (box[0], box[1]), (box[2], box[3]), id2color[_class], linewidth)\n",
    "        for box, _class in zip(gt_boxes, gt_classes):\n",
    "            if _class != 0 or EXCLUDED_BLUE is False:\n",
    "                cv2.rectangle(img_copy1, (box[0], box[1]), (box[2], box[3]), id2color[_class], linewidth)\n",
    "        hstack_np = np.hstack((img, img_copy1, img_copy2))\n",
    "        ax.imshow(hstack_np)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mAP(test_dataset, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.stdout.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feat_eng(bbox_tuple):\n",
    "#     acnes = bbox_tuple[0]\n",
    "#     counter = collections.Counter(acnes)\n",
    "#     feats = counter\n",
    "#     feat = np.zeros(len(label2id))\n",
    "#     for i in range(len(label2id)):\n",
    "#         feat[i] = feats.get(i,0)\n",
    "#     feat_agg = feat.tolist()\n",
    "#     return feat_agg\n",
    "\n",
    "# def get_grading_cls(pred_boxes, pred_class):\n",
    "#     import joblib\n",
    "#     from_file = joblib.load(MODEL_CLASSIFIER)\n",
    "#     feat_agg = feat_eng((pred_class, pred_boxes[:,0],pred_boxes[:,1],pred_boxes[:,2],pred_boxes[:,3]))\n",
    "#     grading = from_file.predict(np.array(feat_agg).reshape(1, -1))\n",
    "#     return grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grading_cls(pred_boxes, pred_class):\n",
    "    counter = collections.Counter(pred_class)\n",
    "    grading = 0\n",
    "    \n",
    "    post_inflammatory = counter.get(0, 0)\n",
    "    inflammatory_lesion = counter.get(1, 0)\n",
    "    acne_scar = counter.get(2, 0)\n",
    "    black_whitehead = counter.get(3, 0)\n",
    "    nodular_lesion = counter.get(4, 0)\n",
    "    \n",
    "    if nodular_lesion >= 2:\n",
    "        grading = 4\n",
    "    elif nodular_lesion == 1:\n",
    "        grading = 3\n",
    "    elif inflammatory_lesion >= 2:\n",
    "        grading = 2\n",
    "    elif (post_inflammatory + acne_scar + black_whitehead >= 10) or (inflammatory_lesion == 1):\n",
    "        grading = 1\n",
    "    elif post_inflammatory + acne_scar + black_whitehead < 10:\n",
    "        grading = 0\n",
    "    else:\n",
    "        grading = 0\n",
    "    return grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "test_df = d\n",
    "it_data_loader = iter(test_data_loader)\n",
    "y_true, y_pred = [], []\n",
    "for i in range(len(test_df[:])):\n",
    "    true_grade = int(test_df['grading'].tolist()[i])\n",
    "    try:\n",
    "        img_id = test_df['id'].tolist()[i]\n",
    "        images, targets = next(it_data_loader)\n",
    "        images = list(img.to(device) for img in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        gt_classes = targets[0]['labels'].cpu().numpy().astype(np.int32)\n",
    "        preds = model(images)\n",
    "        preds = [{k: v.to(cpu) for k, v in t.items()} for t in preds]\n",
    "\n",
    "        ## Groundtruth\n",
    "        boxes = targets[idx]['boxes'].cpu().numpy().astype(np.int32)\n",
    "        sample = images[idx].cpu().numpy()\n",
    "        sample = sample.transpose(1,2,0)\n",
    "\n",
    "        # Pred\n",
    "        pred_scores, pred_boxes, pred_class = get_prediction(preds[idx], threshold=0.2)\n",
    "        pred_boxes = pred_boxes.astype(np.int32)\n",
    "\n",
    "        # Fix\n",
    "        pred_grade = get_grading_cls(pred_boxes, pred_class)\n",
    "        y_true.append(true_grade)\n",
    "        y_pred.append(pred_grade)\n",
    "\n",
    "        gt_classes_c = collections.Counter(gt_classes)\n",
    "        pred_class_c = collections.Counter(pred_class)\n",
    "        levels =list(range(0,5))\n",
    "        trues, preds = [], []\n",
    "        for i in levels:\n",
    "            trues.append(gt_classes_c.get(i, 0))\n",
    "            preds.append(pred_class_c.get(i,0))\n",
    "        c_report = pd.DataFrame({\n",
    "            'level': levels,\n",
    "            'true': trues,\n",
    "            'pred': preds\n",
    "        })\n",
    "        export.append([img_id]+ trues + preds)\n",
    "        \n",
    "\n",
    "#         display(HTML(f'<h1>True Grade: {true_grade} &emsp; Pred Grade: {pred_grade}</h1>'))\n",
    "#         display(c_report)\n",
    "#         plot_with_bbox(sample, boxes, gt_classes, pred_boxes, pred_class)\n",
    "#         print('======================================================================================================================================================================================')\n",
    "\n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = pd.DataFrame(columns=['img_id','t_0','t_1','t_2','t_3','t_4','p_0','p_1','p_2','p_3','p_4'], data=export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [int(i) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_true, y_pred, classes=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_true, y_pred, classes=[0,1,2,3,4], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beeon_venv",
   "language": "python",
   "name": "beeon_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
